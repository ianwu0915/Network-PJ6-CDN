#!/usr/bin/env python3
from http.server import BaseHTTPRequestHandler, HTTPServer
from socketserver import ThreadingMixIn
import time
import sys 
import requests
import gzip
import argparse
import hashlib
import os
import shutil

# origin server to for cdn 
# http://cs5700cdnorigin.ccs.neu.edu:8080/. 

# Size limit for the cache is 20MB (20 * 1024 * 1024 bytes)
CACHE_SIZE = 20 * 1024 * 1024

hostname = "localhost"
port = 8080
 
'''
This class implements a Least Frequently Used (LFU) cache.
It has the following methods:
- get: Get the content of a path from the cache.
- put: Add a path and its content to the cache.
- evict: Remove the least frequently used item from the cache.
- get_safe_filename: Generate a filesystem-safe filename by hashing the key.
- checkIfOriginChanged: Check if the origin hostname changed.
- write_to_disk: Write the cache content to the disk.
- write_frequency_Map_to_disk: Overwrite and Update the frequency map to disk.
- read_frequency_Map_from_disk: Read the frequency map from disk.
- updateFrequency_list: Update the frequency list.
'''
class LFUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.origin_hostname = None
        self.hashed_origin_hostname = None
        
        self.cache = {} # map path to filename
        self.frequencyMap = {} # keep an sorted array of [path, frequency]
        self.current_size = 0
    
    def get_safe_filename(self, path):
        # Generate a filesystem-safe filename by hashing the key.
        return hashlib.sha256(path.encode()).hexdigest()
        
    def get(self, path):
        path = f"{self.origin_hostname}/{path}"
        if path not in self.cache:
            return -1 
        else:
            filename = self.cache[path]
            cache_dir = f"./cache/{self.hashed_origin_hostname}"
            file_path = f"{cache_dir}/{filename}"
            try:
                with open(file_path, 'rb') as f:
                    content = f.read()
                self.updateFrequency_list(path)
                return gzip.decompress(content).decode('utf-8')
            except (FileNotFoundError, OSError) as e:
                print(f"Error reading file {filename}: {e}")
                return -1
    
    # check if the origin hostname changed
    # if it changed, delete the previous origin directory in the cache
    # and create a new origin directory
    # Set the current origin hostname to the new origin hostname
    def checkIfOriginChanged(self, origin):
        print("Checking if origin changed")
        print("Current Origin Hostname: ", origin)
        # if self.origin_hostname == origin:
        #     print("Origin hostname has not changed")
        #     return 
        
        # Create a directory called cache
        os.makedirs("./cache", exist_ok=True)
        
        self.origin_hostname = origin
        self.hashed_origin_hostname = self.get_safe_filename(origin)

        # Check if the origin hostname changed by
        # checking if the current origin directory folder is in the ./cache directory
        if not os.path.exists(f"./cache/{self.hashed_origin_hostname}"):
            # Delete other origin directories in the disk to save space
            # by deleting the previous origin directory in the cache directory
            for dir_name in os.listdir("./cache"):
                dir_path = os.path.join("./cache", dir_name)
                shutil.rmtree(dir_path)
            
            # create the current origin directory
            print("Creating new origin directory")
            os.makedirs(f"./cache/{self.hashed_origin_hostname}", exist_ok=True)

        # Previous cache file exists
        # Retrieve the frequency map and current size from disk 
        else:
            # Read the frequency map from disk
            print("Reading frequency map from disk")
            self.read_frequency_Map_from_disk()
             
    def put(self, path, content):
        
        file_path = f"{self.origin_hostname}/{path}"
        if file_path in self.cache:
            raise ValueError("Key already exists in cache")
        
        file_size = sys.getsizeof(file_path) + sys.getsizeof(gzip.compress(content.encode('utf-8')))
        
        while self.cache and self.current_size + file_size > self.capacity:
            print("#############################")
            print("Cache is full, Evicting the least frequently used item")
            print("file size: ", file_size)
            print("Current size + file size: ", self.current_size + file_size)
            print("Cache size: ", self.capacity)
            print("#############################")
            self.evict()
        
        # [path: hashed_filename]
        hashed_file_name = self.get_safe_filename(path)
        
        self.cache[file_path] = hashed_file_name
        print("Add to cache: ", file_path, hashed_file_name)
        print("Cache: ", self.cache)
        self.write_to_disk(hashed_file_name, content)
        
        # update the current size with real file size
        file_size = os.path.getsize(f"./cache/{self.hashed_origin_hostname}/{self.cache[file_path]}")
        self.current_size += file_size
        print("#############################")
        print(f"Current Cache Size Used: {self.current_size / CACHE_SIZE * 100:.2f} %")
        print("#############################")
        self.frequencyMap[file_path] = 1
        self.write_frequency_Map_to_disk()
    
    # Write the cache content to the disk
    def write_to_disk(self, hashed_file_name, content):
        
        cache_dir = f"./cache/{self.hashed_origin_hostname}"
        file_path = f"{cache_dir}/{hashed_file_name}"
        
        try:
            os.makedirs(cache_dir, exist_ok=True)  # Ensure the cache directory exists
            file_content = gzip.compress(content.encode('utf-8'))
            with open(file_path, 'wb') as f:
                f.write(file_content)
        except OSError as e:
            print(f"Failed to write file {file_path}: {e}")
    
    # Overwrite and Update the frequency map to disk
    def write_frequency_Map_to_disk(self):
        # open the file in write mode
        # overwrite the file if it exists
        with open(f"./cache/{self.hashed_origin_hostname}/frequencyMap.txt", "w") as f:
            # write the current size of the cache
            f.write("current size: " + str(self.current_size) + "\n")
            for path, freq in self.frequencyMap.items():
                f.write(f"{path}-> {freq}\n")
    
    # read the frequency map from disk
    def read_frequency_Map_from_disk(self):
        try:
            with open(f"./cache/{self.hashed_origin_hostname}/frequencyMap.txt", "r") as f:
                for line in f:
                    if "current size" in line:
                        self.current_size = int(line.split(":")[1])
                        print("#### Current size: ", self.current_size)
                        continue
                    path, frequency = line.split("->")
                    print("Path: ", path)
                    self.frequencyMap[path] = int(frequency)
                print("FrequencyMap: ", self.frequencyMap)
        except FileNotFoundError:
            print("File not found")
    
    def updateFrequency_list(self, key):
        # find the path in the frequency list
        print("#############################")
        print("Updating frequency list")
        self.frequencyMap[key] += 1
        self.write_frequency_Map_to_disk()
                    
    def evict(self):
        
        if not self.frequencyMap:
            print("Cache is empty, no items to evict.")
            return
        
        print(f"Current Cache Size Used: {self.current_size / CACHE_SIZE * 100:.2f} %")
        
        # remove the least Frequently used item from the sorted frequency hashmap
        # and remove the file from the filesystem
        
        # sort the frequency key value pair by frequency
        for path, freq in sorted(self.frequencyMap.items(), key = lambda x: x[1]):
            # check the frequency from the beginning and see if it's in the cache
            if path in self.cache:
                # remove the file from the filesystem
                file_name = self.cache[path]
                file_path = f"./cache/{self.hashed_origin_hostname}/{file_name}"
                file_size = 0
                try:
                    file_size = os.path.getsize(file_path)
                    os.remove(file_path)
                except FileNotFoundError:
                    print("File not found")
                    continue
                    
                self.current_size -= file_size
                
                # remove the item from the cache
                del self.cache[path]
                
                break
        
LFUcache = LFUCache(CACHE_SIZE)

'''
This class is a subclass of the HTTP server class. 
It overrides the constructor
to take an additional argument, origin, which
is the origin server URL for the CDN.
'''
class MyHTTPServer(ThreadingMixIn, HTTPServer):
    def __init__(self, server_address, handler_class, origin):
        self.origin = origin
        super().__init__(server_address, handler_class)
        
'''
This class is a subclass of the Base HTTPRequestHandler class. 
It overrides the do_GET method to handle GET requests.
'''
class MyHandler(BaseHTTPRequestHandler):

    # handle GET requests
    def do_GET(self):  
        global LFUcache
        print("Requesting for: ", self.path)
        
         # Check if the request is for the grading beacon
        if self.path == "/grading/beacon":
            self.send_response(204)  # 204 No Content
            self.end_headers()
            return
        
        # if the path is in the cache, return the content
        LFUcache.checkIfOriginChanged(self.server.origin)
        response_content = LFUcache.get(self.path)
        if response_content != -1:
            # response_content = LFUcache.get(self.path)
            print("######## Cache Hit!!!! ########")
            
        # if the path is not in the cache, fetch from origin server
        else:
            print("######## Cache miss!!!! ########")
            # fetch from origin server 
            response_content = self.fetch_from_origin_server(self.path)
            if not response_content:
                self.send_response(404)
                self.send_header("Content-type", "text/html")
                self.end_headers()
                self.wfile.write(b"404 Not Found")
                return
           
            LFUcache.put(self.path, response_content)
            print("Add to cache successful")
            print("Current Cache Size: ", LFUcache.current_size)
        
        print("GET request received")
        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(response_content.encode('utf-8'))
        
    # fetch content from the origin server if the path is not in the cache
    def fetch_from_origin_server(self, path):
        origin_url = f"{self.server.origin}{path}"
    
        print("Fetching from origin server")
        try: 
            response = requests.get(origin_url)
            response.raise_for_status()
            if 'gzip' in response.headers.get('Content-Encoding', ''):
                content = gzip.decompress(response.content).decode('utf-8')
            else:
                content = response.content.decode('utf-8')
                
            return content
        except requests.exceptions.HTTPError as err:
            print(f"Error: {err}")
            return None 



# This function runs the HTTP server.       
def run(server_class=MyHTTPServer, handler_class=MyHandler, port=8080, origin =""):
    server_address = ('', port)
    httpd = server_class(server_address, handler_class, origin)
    print(f'Starting httpd on port {port}...')
    httpd.serve_forever()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="HTTP CDN Server")
    parser.add_argument('-p', '--port', type=int, help='Port number the HTTP server binds to', required=True)
    parser.add_argument('-o', '--origin', type=str, help='Origin server URL for the CDN', required=True)

    args = parser.parse_args()

    run(port=args.port, origin=args.origin)
                                    