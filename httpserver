#!/usr/bin/env python3
from http.server import BaseHTTPRequestHandler, HTTPServer
from socketserver import ThreadingMixIn
import time
import sys 
import requests
import gzip
import argparse
import hashlib
import os
import shutil
import psutil
import json

# Size limit for the cache is 20MB (20 * 1024 * 1024 bytes)
CACHE_SIZE = 20 * 1024 * 1024

class LFUCache:
    """
    A class representing a Least Frequently Used (LFU) cache mechanism.

    Attributes:
        capacity (int): The maximum storage capacity of the cache.
        origin_hostname (str): The hostname of the origin server.
        hashed_origin_hostname (str): The hashed version of the origin hostname for unique directory naming.
        cache (dict): A dictionary to store cached data with paths as keys and filenames as values.
        frequencyMap (dict): A dictionary to store access frequencies of cached items.
        current_size (int): The current size of the cache used.
    """
    def __init__(self, capacity):
        """
        Constructs all the necessary attributes for the LFU cache object.

        Parameters:
            capacity (int): The maximum storage capacity of the cache (in bytes).
        """
        self.capacity = capacity
        self.origin_hostname = None
        self.hashed_origin_hostname = None
        self.cache = {} 
        self.frequencyMap = {} 
        self.current_size = 0
    
    def get_safe_filename(self, path):
        """
        Generates a filesystem-safe filename by hashing the path.

        Parameters:
            path (str): The file path to hash.

        Returns:
            str: A hashed version of the input path.
        """
        return hashlib.sha256(path.encode()).hexdigest()
        
    def get(self, path):
        """
        Retrieves the content of the given path from the cache.

        Parameters:
            path (str): The path of the file to retrieve.

        Returns:
            str: The content of the file if it is in the cache, otherwise -1.
        """
        path = f"{self.origin_hostname}/{path}"
        if path not in self.cache:
            return -1 
        else:
            filename = self.cache[path]
            cache_dir = f"./cache/{self.hashed_origin_hostname}"
            file_path = f"{cache_dir}/{filename}"
            try:
                with open(file_path, 'rb') as f:
                    content = f.read()
                self.updateFrequency_list(path)
                return gzip.decompress(content).decode('utf-8')
            except (FileNotFoundError, OSError) as e:
                print(f"Error reading file {filename}: {e}")
                return -1
    
    def checkIfOriginChanged(self, origin):
        """
        Checks and updates the cache directory if the origin server hostname has changed.

        Parameters:
            origin (str): The hostname of the origin server.
        """
        
        if self.origin_hostname == origin:
            return
        
        # Create a directory called cache
        os.makedirs("./cache", exist_ok=True)
        
        self.origin_hostname = origin
        self.hashed_origin_hostname = self.get_safe_filename(origin)

        # Check if the origin hostname changed by
        # checking if the current origin directory folder is in the ./cache directory
        if not os.path.exists(f"./cache/{self.hashed_origin_hostname}"):
            # Delete other origin directories in the disk to save space
            # by deleting the previous origin directory in the cache directory
            for dir_name in os.listdir("./cache"):
                dir_path = os.path.join("./cache", dir_name)
                shutil.rmtree(dir_path)
            
            # create the current origin directory
            os.makedirs(f"./cache/{self.hashed_origin_hostname}", exist_ok=True)

        # Previous cache file exists
        # Retrieve the frequency map and current size from disk 
        else:
            # Read the frequency map from disk
            self.read_frequency_Map_from_disk()
             
    def put(self, path, content):
        """
        Adds a new path and its content to the cache. If the cache exceeds its capacity,
        evicts the least frequently used items.

        Parameters:
            path (str): The path of the file to cache.
            content (str): The content of the file to cache.
        """ 
        file_path = f"{self.origin_hostname}/{path}"
        if file_path in self.cache:
            raise ValueError("Key already exists in cache")
        
        file_size = sys.getsizeof(file_path) + sys.getsizeof(gzip.compress(content.encode('utf-8')))
        
        while self.cache and self.current_size + file_size > self.capacity:
            self.evict()
        
        # [path: hashed_filename]
        hashed_file_name = self.get_safe_filename(file_path)
        
        self.cache[file_path] = hashed_file_name
        self.write_to_disk(hashed_file_name, content)
        
        # update the current size with real file size
        file_size = os.path.getsize(f"./cache/{self.hashed_origin_hostname}/{self.cache[file_path]}")
        self.current_size += file_size
        self.frequencyMap[file_path] = 1
        self.write_frequency_Map_to_disk()

    def write_to_disk(self, hashed_file_name, content):
        """
        Writes the compressed content to the disk.

        Parameters:
            hashed_file_name (str): The hashed file name to store the content.
            content (str): The content to be written to the disk.
        """
        cache_dir = f"./cache/{self.hashed_origin_hostname}"
        file_path = f"{cache_dir}/{hashed_file_name}"
        
        try:
            os.makedirs(cache_dir, exist_ok=True)  # Ensure the cache directory exists
            file_content = gzip.compress(content.encode('utf-8'))
            with open(file_path, 'wb') as f:
                f.write(file_content)
        except OSError as e:
            print(f"Failed to write file {file_path}: {e}")
    
    def write_frequency_Map_to_disk(self):
        '''
        Write the frequency map to disk.
        '''
        
        # open the file in write mode
        # overwrite the file if it exists
        with open(f"./cache/{self.hashed_origin_hostname}/frequencyMap.txt", "w") as f:
            # write the current size of the cache
            f.write("current size: " + str(self.current_size) + "\n")
            for path, freq in self.frequencyMap.items():
                f.write(f"{path}-> {freq}\n")
    
    # read the frequency map from disk
    def read_frequency_Map_from_disk(self):
        """
        Reads the frequency map from the disk to update the cache management policies based on access frequencies.
        """
        try:
            with open(f"./cache/{self.hashed_origin_hostname}/frequencyMap.txt", "r") as f:
                for line in f:
                    if "current size" in line:
                        self.current_size = int(line.split(":")[1])
                        continue
                    path, frequency = line.split("->")
                    self.frequencyMap[path] = int(frequency)
                    
                    if path not in self.cache:
                        self.cache[path] = self.get_safe_filename(path)
                    
        except FileNotFoundError:
            print("File not found")
    
    
    # Update the frequency list
    def updateFrequency_list(self, key):
        """
        Updates the access frequency list for a given cache item.

        Parameters:
            key (str): The cache key corresponding to the item whose frequency is to be updated.
        """
        # find the path in the frequency list
        self.frequencyMap[key] += 1
        self.write_frequency_Map_to_disk()
                    
    def evict(self):
        """
        Evicts the least frequently used item from the cache based on the access frequency in the frequency map.
        """
        if not self.frequencyMap:
            return
        
        # Remove the least Frequently used item from the sorted frequency hashmap
        # and remove the file from the filesystem
        # sort the frequency key value pair by frequency
        for path, freq in sorted(self.frequencyMap.items(), key = lambda x: x[1]):
            # check the frequency from the beginning and see if it's in the cache
            if path in self.cache:
                # remove the file from the filesystem
                file_name = self.cache[path]
                file_path = f"./cache/{self.hashed_origin_hostname}/{file_name}"
                file_size = 0
                try:
                    file_size = os.path.getsize(file_path)
                    os.remove(file_path)
                except FileNotFoundError:
                    print("File not found")
                    continue
                    
                self.current_size -= file_size
                
                # remove the item from the cache
                del self.cache[path]
                
                break
        
LFUcache = LFUCache(CACHE_SIZE)

class MyHTTPServer(ThreadingMixIn, HTTPServer):
    """
    A threaded HTTP server class that handles requests in separate threads.

    Attributes:
        origin (str): The origin server URL.
    """
    def __init__(self, server_address, handler_class, origin):
        """
        Initializes the HTTP server with the specified server address, handler class, and origin server URL.

        Parameters:
            server_address (tuple): The host and port to which the server is bound.
            handler_class (BaseHTTPRequestHandler): The handler class for HTTP requests.
            origin (str): The origin server URL.
        """
        self.origin = origin
        super().__init__(server_address, handler_class)

class MyHandler(BaseHTTPRequestHandler):
    """
    HTTP request handler class that handles GET requests.

    Methods:
        do_GET(self): Handles the GET HTTP request.
    """
    def do_GET(self):  
        """
        Responds to a GET request. Loads content from the cache or fetches from the origin server if not available in the cache.
        """
        global LFUcache
        print("Requesting for: ", self.path)
        
         # Check if the request is for the grading beacon
        if self.path == "/grading/beacon":
            self.send_response(204)  # 204 No Content
            self.end_headers()
            return
        
        if self.path == "/server-load":
            self.handle_server_load()
            return
        
        # if the path is in the cache, return the content
        LFUcache.checkIfOriginChanged(self.server.origin)
        response_content = LFUcache.get(self.path)
        if response_content != -1:
            # response_content = LFUcache.get(self.path)
            # print("######## Cache Hit!!!! ########")
            
        # if the path is not in the cache, fetch from origin server
        else:
            # print("######## Cache miss!!!! ########")
            # fetch from origin server 
            response_content = self.fetch_from_origin_server(self.path)
            if not response_content:
                self.send_response(404)
                self.send_header("Content-type", "text/html")
                self.end_headers()
                self.wfile.write(b"404 Not Found")
                return
           
            LFUcache.put(self.path, response_content)
        
        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(response_content.encode('utf-8'))
    
    def handle_server_load(self):
        """
        Handles the server load by checking the CPU and memory usage.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        cpu_usage_json = {"cpu_usage": cpu_usage}
        
        json_response = json.dumps(cpu_usage_json)
        
        # convert cpu_usage into json format
        # send the cpu usage to the monitoring server
        self.send_response(200)
        self.send_header("Content-type", "application/json")
        self.end_headers()
        self.wfile.write(json_response.encode('utf-8'))
        
    def fetch_from_origin_server(self, path):
        """
        Fetches content from the origin server if it is not available in the cache.

        Parameters:
            path (str): The path for which content needs to be fetched.

        Returns:
            str: The content fetched from the origin server.
        """
        origin_url = f"{self.server.origin}{path}"
    
        try: 
            response = requests.get(origin_url)
            response.raise_for_status()
            if 'gzip' in response.headers.get('Content-Encoding', ''):
                content = gzip.decompress(response.content).decode('utf-8')
            else:
                content = response.content.decode('utf-8')        
            return content
        
        except requests.exceptions.HTTPError as err:
            print(f"Error: {err}")
            return None 

def run(server_class=MyHTTPServer, handler_class=MyHandler, port=8080, origin =""):
    """
    Runs the HTTP server with the specified parameters.

    Parameters:
        server_class (HTTPServer): The server class to use for running the HTTP server.
        handler_class (BaseHTTPRequestHandler): The request handler class.
        port (int): The port on which the server should listen.
        origin (str): The origin server URL.
    """
    server_address = ('', port)
    httpd = server_class(server_address, handler_class, origin)
    print(f'Starting httpd on port {port}...')
    httpd.serve_forever()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="HTTP CDN Server")
    parser.add_argument('-p', '--port', type=int, help='Port number the HTTP server binds to', required=True)
    parser.add_argument('-o', '--origin', type=str, help='Origin server URL for the CDN', required=True)

    args = parser.parse_args()

    run(port=args.port, origin=args.origin)
                                    